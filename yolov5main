/*** 1) Libraries and Namespaces ***/

#include <opencv2/opencv.hpp>
#include <fstream>
using namespace cv;
using namespace std;
using namespace cv::dnn;


/*** 2) Global Parameters ***/

const string CLASS_NAME = "hand";
// costants
const float INPUT_WIDTH = 640.0;
const float INPUT_HEIGHT = 640.0;
const float SCORE_THRESHOLD = 0.5;
const float NMS_THRESHOLD = 0.45;
const float CONFIDENCE_THRESHOLD = 0.45;
// text
const float FONT_SCALE = 0.7;
const int FONT_FACE = FONT_HERSHEY_SIMPLEX;
const int THICKNESS = 1;
// colors
Scalar BLACK = Scalar(0, 0, 0);
Scalar BLUE = Scalar(255, 178, 50);
Scalar YELLOW = Scalar(0, 255, 255);
Scalar RED = Scalar(0, 0, 255);


/*** 3) Draw Label ***/

void draw_label(Mat& input_image, string label, int left, int top)
{
    // Display the label at the top of the bounding box
    int baseLine;
    Size label_size = getTextSize(label, FONT_FACE, FONT_SCALE, THICKNESS, &baseLine);
    top = max(top, label_size.height);
    // Top left corner
    Point tlc = Point(left, top);
    // Bottom right corner
    Point brc = Point(left + label_size.width, top + label_size.height + baseLine);
    // Draw white rectangle
    rectangle(input_image, tlc, brc, BLACK, FILLED);
    // Put the label on the black rectangle
    putText(input_image, label, Point(left, top + label_size.height), FONT_FACE, FONT_SCALE, YELLOW, THICKNESS);
}


/*** 4) Pre-Processing ***/

vector<Mat> pre_process(const Mat& input_image, Net& net)
{
    // Convert to blob
    Mat blob;
    blobFromImage(input_image, blob, 1. / 255., Size(INPUT_WIDTH, INPUT_HEIGHT), Scalar(), true, false);

    net.setInput(blob);

    // Forward propagate
    vector<Mat> outputs;
    net.forward(outputs, net.getUnconnectedOutLayersNames());

    return outputs;
}


/*** 5) Post-Processing ***/

Mat post_process(Mat& input_image, const vector<Mat>& outputs, const vector<Rect>& gtBoxes, vector<Rect>& boxes)
{
    // Only 1 class id (0: hand)
    Point class_id;
    class_id.x = 0;
    class_id.y = 0;
    // Initialize vectors to hold respective outputs while unwrapping detections
    vector<float> confidences;
    // Resizing factor
    float x_factor = input_image.cols / INPUT_WIDTH;
    float y_factor = input_image.rows / INPUT_HEIGHT;
    float* data = (float*)outputs[0].data;
    const int dimensions = 6;

    /* A. Filter Good Detections */

    // 25200 for default size 640
    const int rows = 25200;
    // Iterate through 25200 detections
    for (int i = 0; i < rows; ++i)
    {
        float confidence = data[4];
        // Discard bad detections and continue
        if (confidence >= CONFIDENCE_THRESHOLD)
        {
            // Store class ID and confidence in the pre-defined respective vectors
            confidences.push_back(confidence);
            // Center
            float cx = data[0];
            float cy = data[1];
            // Box dimension
            float w = data[2];
            float h = data[3];
            // Bounding box coordinates
            int left = int((cx - 0.5 * w) * x_factor);
            int top = int((cy - 0.5 * h) * y_factor);
            int width = int(w * x_factor);
            int height = int(h * y_factor);
            // Store good detections in the boxes vector
            boxes.push_back(Rect(left, top, width, height));
        }
        // Jump to the next row
        data += dimensions;
    }

    /* B. Remove Overlapping Boxes */

    // Perform Non-Maximum Suppression and draw predictions
    vector<int> indices;
    NMSBoxes(boxes, confidences, SCORE_THRESHOLD, NMS_THRESHOLD, indices);
    // *TEMP* Draw ground truth bounding box
    // if (gtBoxes.size() != 0)
    for (int i = 0; i < gtBoxes.size(); i++)
        rectangle(input_image, Point(gtBoxes[i].x, gtBoxes[i].y), Point(gtBoxes[i].x + gtBoxes[i].width, gtBoxes[i].y + gtBoxes[i].height), RED, 3 * THICKNESS);
    for (int i = 0; i < indices.size(); i++)
    {
        int idx = indices[i];
        Rect box = boxes[idx];
        int left = box.x;
        int top = box.y;
        int width = box.width;
        int height = box.height;
        // Draw bounding box
        rectangle(input_image, Point(left, top), Point(left + width, top + height), BLUE, 3 * THICKNESS);
        // Get the label for the class name and its confidence
        string label = format("%.2f", confidences[idx]);
        // label = CLASS_NAME + ":" + label;
        // Draw class labels
        draw_label(input_image, label, left, top);
    }
    return input_image;
}


/*** 6) IoU Metric ***/

float bboxes_iou(Rect gtBox, Rect predBox)
{
    // Coordinates for intersection rectangle
    int xA = max(gtBox.x, predBox.x);
    int yA = max(gtBox.y, predBox.y);
    int xB = min(gtBox.x + gtBox.width, predBox.x + predBox.width);
    int yB = min(gtBox.y + gtBox.height, predBox.y + predBox.height);
    // Area of intersection rectangle
    float interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1);
    // Area of predicted and ground truth bounding boxes
    //float gtBoxArea = (gtBox.width + 1) * (gtBox.height + 1);
    //float predBoxArea = (predBox.width + 1) * (predBox.height + 1);
    // IoU as the intersection area of the two boxes divided by their union area
    float iou = interArea / float(gtBox.area() + predBox.area() - interArea);
    return iou;
}


/*** 7) Hand Segmentation ***/

Mat hand_segmentation(Mat& frame, const vector<Rect>& boxes)
{
    Mat temp_img, mask, bgdModel, fgdModel;
    cvtColor(frame, frame, COLOR_RGBA2RGB, 0);
    // Final image (initialized full black) to return at the end
    Mat final_img(frame.rows, frame.cols, frame.type(), BLACK);
    for (int i = 0; i < boxes.size(); i++)
    {
        // Use a temporary image for each boundig box
        frame.copyTo(temp_img);
        Rect rect = boxes[i];
        grabCut(temp_img, mask, rect, bgdModel, fgdModel, 1, GC_INIT_WITH_RECT);
        // Draw background (black) or hand (white) pixels on temporary image
        for (int i = 0; i < frame.rows; i++)
            for (int j = 0; j < frame.cols; j++)
                if (mask.at<uchar>(i, j) == 0 || mask.at<uchar>(i, j) == 2)
                {
                    temp_img.at<Vec3b>(i, j)[0] = 0;
                    temp_img.at<Vec3b>(i, j)[1] = 0;
                    temp_img.at<Vec3b>(i, j)[2] = 0;
                }
                else
                {
                    temp_img.at<Vec3b>(i, j)[0] = 255;
                    temp_img.at<Vec3b>(i, j)[1] = 255;
                    temp_img.at<Vec3b>(i, j)[2] = 255;
                }
        // Partial sum of current temporary image into final image
        for (int i = 0; i < frame.rows; i++)
            for (int j = 0; j < frame.cols; j++)
                if (final_img.at<Vec3b>(i, j)[0] == 0 && final_img.at<Vec3b>(i, j)[1] == 0 && final_img.at<Vec3b>(i, j)[2] == 0)
                {
                    final_img.at<Vec3b>(i, j)[0] += temp_img.at<Vec3b>(i, j)[0];
                    final_img.at<Vec3b>(i, j)[1] += temp_img.at<Vec3b>(i, j)[1];
                    final_img.at<Vec3b>(i, j)[2] += temp_img.at<Vec3b>(i, j)[2];
                }
        // *TEMP* Draw grab rect
        rectangle(final_img, Point(boxes[i].x, boxes[i].y), Point(boxes[i].x + boxes[i].width, boxes[i].y + boxes[i].height), YELLOW);
    }
    return final_img;
}


/*** 8) IoU Metric ***/

vector<int> pixel_accuracy(const Mat& gtMask, const Mat& predMask)
{
    // Counters for pixels in ground truth mask
    int gt_hand = 0, gt_non_hand = 0;
    // Accuracy parameters
    float acc_hand = 0.0, acc_non_hand = 0.0;

    // Calculate wrong hand pixels and wrong non-hand pixels
    for (int i = 0; i < gtMask.rows; i++)
        for (int j = 0; j < gtMask.cols; j++)
        {
            if (gtMask.at<Vec3b>(i, j)[0] == 0 && gtMask.at<Vec3b>(i, j)[1] == 0 && gtMask.at<Vec3b>(i, j)[2] == 0)
                gt_non_hand++;
            else
                gt_hand++;

            if (gtMask.at<Vec3b>(i, j) != predMask.at<Vec3b>(i, j))
                // if pixel: truth = non-hand AND predicted = hand
                if (gtMask.at<Vec3b>(i, j)[0] == 0 && gtMask.at<Vec3b>(i, j)[1] == 0 && gtMask.at<Vec3b>(i, j)[2] == 0)
                    acc_non_hand++;
                // if pixel: truth = hand AND predicted = non-hand
                else
                    acc_hand++;
        }
    // Hand accuracy = (# real hand pixels - # hand pixels not found) / # real hand pixels
    acc_hand = (gt_hand - acc_hand) / gt_hand;
    // Non-hand accuracy = (# real non-hand pixels - # non-hand pixels not found) / # real non-hand pixels
    acc_non_hand = (gt_non_hand - acc_non_hand) / gt_non_hand;

    vector<int> vec;
    vec.push_back(acc_hand);
    vec.push_back(acc_non_hand);
    return vec;
}


/*** -> Main Function ***/

int main()
{
    // Paths
    string image_path = "29.jpg";// "rgb/23.jpg";
    string labels_path = "29.txt";// "det/23.txt";
    string mask_path = "29.png";// "det/23.txt";
    Net net;
    Mat frame, frame_copy;
    vector<Mat> detections;
    vector<Rect> labels, predBoxes;
    ifstream file;
    int x, y, w, h;

    // Load image
    frame = imread(image_path);
    // Load labels
    file = ifstream(labels_path);
    while (file >> x >> y >> w >> h)
        labels.push_back(Rect(x, y, w, h));
    // Load model
    net = readNet("best50s.onnx");

    // Process image and labels
    frame.copyTo(frame_copy); // deep copy of image
    detections = pre_process(frame, net);
    post_process(frame_copy, detections, labels, predBoxes);

    namedWindow("Output", WINDOW_NORMAL);
    imshow("Output", frame_copy);
    waitKey(0);

    // Image segmentation
    Mat gtMask = imread(mask_path);
    Mat predMask = hand_segmentation(frame, predBoxes);
    namedWindow("Segmented image", WINDOW_NORMAL);
    imshow("Segmented image", gtMask);
    imshow("Segmented image", predMask);
    waitKey(0);

    vector<int> acc = pixel_accuracy(gtMask, predMask);
    cout << acc[0] << ", " << acc[1];

    return 0;
}
