{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbjTHz5-_3Db"
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone yolov5 repository and install requirments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qan8cen2tivg",
    "outputId": "31cc8f94-c0ae-4566-b6d6-6d09278aee52"
   },
   "outputs": [],
   "source": [
    "!pip install -r yolov5/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Qu-JTwU4gFNH"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('cv-dataset.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "61793yKJ4PuZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ v6.1-325-g3e85863 Python-3.7.13 torch-1.11.0+cu102 CUDA:0 (Tesla T4, 15110MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 40.9/78.2 GB disk)\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5\n",
    "import torch\n",
    "import utils\n",
    "display = utils.notebook_init()\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNd4G8r0ETvq"
   },
   "source": [
    "### Training (on custom data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8n17FsCZwMJ"
   },
   "source": [
    "Train YOLOv5m on our custom dataset for 500 epochs with batch_size = 16 and image_size = 640x640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rHXJvnceEVBV",
    "outputId": "0c223656-5887-48b3-ac7c-92bba4f0e57b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/yolov5/data/custom_data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=500, batch_size=16, imgsz=640, rect=False, resume=/content/gdrive/MyDrive/backup6/weights/last.pt, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (Docker image), for updates see https://github.com/ultralytics/yolov5\n",
      "Resuming training from /content/gdrive/MyDrive/backup6/weights/last.pt\n",
      "YOLOv5 ðŸš€ v6.1-325-g3e85863 Python-3.7.13 torch-1.11.0+cu102 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/gdrive/MyDrive', view at http://localhost:6006/\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
      "100% 755k/755k [00:00<00:00, 17.1MB/s]\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     24246  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model summary: 369 layers, 20871318 parameters, 20871318 gradients, 48.2 GFLOPs\n",
      "\n",
      "Transferred 481/481 items from /content/gdrive/MyDrive/backup6/weights/last.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 79 weight (no decay), 82 weight, 82 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/cv-dataset/train/labels' images and labels...5070 found, 0 missing, 12 empty, 0 corrupt: 100% 5070/5070 [00:02<00:00, 2101.72it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/cv-dataset/train/images/CARDS_LIVINGROOM_T_B_frame_1750_jpg.rf.79a407608a2b9ce8ae97bc8cc9848744.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/cv-dataset/train/labels.cache\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (3.5GB ram): 100% 5070/5070 [00:53<00:00, 94.67it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/cv-dataset/val/labels' images and labels...50 found, 0 missing, 0 empty, 0 corrupt: 100% 50/50 [00:00<00:00, 526.21it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/cv-dataset/val/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 50/50 [00:01<00:00, 32.09it/s]\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m/content/gdrive/MyDrive/backup6\u001b[0m\n",
      "Starting training for 500 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "   480/499     6.25G  0.007681  0.008246         0        64       640: 100% 317/317 [02:29<00:00,  2.12it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  3.57it/s]\n",
      "                 all         50        140      0.948        0.8      0.887      0.679\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "   481/499     6.25G  0.007694  0.008457         0        93       640: 100% 317/317 [02:30<00:00,  2.11it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  3.53it/s]\n",
      "                 all         50        140      0.947        0.8      0.887      0.677\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "   482/499     6.25G  0.007605  0.008125         0        73       640: 100% 317/317 [02:29<00:00,  2.12it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  3.60it/s]\n",
      "                 all         50        140      0.947        0.8      0.887      0.678\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "   483/499     6.25G  0.007651  0.008162         0        88       640: 100% 317/317 [02:29<00:00,  2.12it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  3.59it/s]\n",
      "                 all         50        140      0.948        0.8      0.887      0.678\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "   484/499     6.25G  0.007585  0.008084         0        86       640: 100% 317/317 [02:29<00:00,  2.11it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  3.47it/s]\n",
      "                 all         50        140      0.948        0.8      0.887      0.678\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "   485/499     6.25G  0.007611  0.008245         0        85       640: 100% 317/317 [02:29<00:00,  2.11it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  3.55it/s]\n",
      "                 all         50        140      0.948        0.8      0.887      0.677\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "   486/499     6.25G  0.007545  0.008171         0        96       640: 100% 317/317 [02:29<00:00,  2.11it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  3.57it/s]\n",
      "                 all         50        140      0.948        0.8      0.887      0.677\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "   487/499     6.25G  0.007453  0.007915         0        89       640: 100% 317/317 [02:29<00:00,  2.11it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  3.54it/s]\n",
      "                 all         50        140      0.948        0.8      0.887      0.677\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "   488/499     6.25G  0.007626  0.008226         0        76       640: 100% 317/317 [02:29<00:00,  2.11it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  3.54it/s]\n",
      "                 all         50        140      0.948        0.8      0.887      0.677\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "   489/499     6.25G  0.007559   0.00818         0        97       640: 100% 317/317 [02:29<00:00,  2.12it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  3.56it/s]\n",
      "                 all         50        140      0.947        0.8      0.887      0.678\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "   490/499     6.25G  0.007532  0.008153         0        97       640: 100% 317/317 [02:29<00:00,  2.11it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  3.55it/s]\n",
      "                 all         50        140      0.948        0.8      0.887      0.678\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "   491/499     6.25G  0.007578  0.008233         0        71       640: 100% 317/317 [02:29<00:00,  2.12it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  3.62it/s]\n",
      "                 all         50        140      0.948        0.8      0.887      0.678\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "   492/499     6.25G  0.007493  0.008153         0        84       640: 100% 317/317 [02:29<00:00,  2.11it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  3.58it/s]\n",
      "                 all         50        140      0.949        0.8      0.887      0.678\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "   493/499     6.25G  0.007474  0.008185         0        85       640: 100% 317/317 [02:29<00:00,  2.11it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  3.55it/s]\n",
      "                 all         50        140      0.919      0.814      0.887      0.678\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "   494/499     6.25G  0.007522  0.008122         0        75       640: 100% 317/317 [02:30<00:00,  2.11it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  3.52it/s]\n",
      "                 all         50        140      0.918      0.814      0.887      0.679\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "   495/499     6.25G  0.007391  0.007982         0        99       640: 100% 317/317 [02:29<00:00,  2.11it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  3.43it/s]\n",
      "                 all         50        140      0.918      0.814      0.887      0.678\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "   496/499     6.25G  0.007435  0.008086         0        81       640: 100% 317/317 [02:30<00:00,  2.11it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  3.54it/s]\n",
      "                 all         50        140      0.918      0.814      0.888      0.679\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "   497/499     6.25G  0.007414  0.007996         0        77       640: 100% 317/317 [02:29<00:00,  2.11it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  3.60it/s]\n",
      "                 all         50        140      0.918      0.814      0.887      0.679\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "   498/499     6.25G  0.007325  0.008123         0        91       640: 100% 317/317 [02:30<00:00,  2.11it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  3.59it/s]\n",
      "                 all         50        140      0.918      0.814      0.887      0.678\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "   499/499     6.25G  0.007353  0.008013         0        96       640: 100% 317/317 [02:30<00:00,  2.11it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  3.56it/s]\n",
      "                 all         50        140      0.918      0.814      0.887      0.678\n",
      "\n",
      "74 epochs completed in 3.115 hours.\n",
      "Optimizer stripped from /content/gdrive/MyDrive/backup6/weights/last.pt, 42.2MB\n",
      "Optimizer stripped from /content/gdrive/MyDrive/backup6/weights/best.pt, 42.2MB\n",
      "\n",
      "Validating /content/gdrive/MyDrive/backup6/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 290 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.55it/s]\n",
      "                 all         50        140      0.951      0.827      0.893       0.69\n",
      "Results saved to \u001b[1m/content/gdrive/MyDrive/backup6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python yolov5/train.py --img 640 --batch 16 --epochs 1 --data custom_data.yaml --weights yolov5m.pt --cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79pLenhAZuOh"
   },
   "source": [
    "To resume training in case of early stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zBI5f6HXZOsI"
   },
   "outputs": [],
   "source": [
    "#!python yolov5/train.py --img 640 --batch 16 --epochs 500 --data custom_data.yaml --resume yolov5/runs/train/exp/weights/last.pt --cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8KRFvlCJk4q"
   },
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2R-7eOcvZg-R"
   },
   "source": [
    "Validate last resulting model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qDe_sEWzFnVN",
    "outputId": "07d46063-be42-4b4b-89e4-0b01782ed6c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolov5/data/custom_data.yaml, weights=['/content/gdrive/MyDrive/yolov5/models/last500m.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.65, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False\n",
      "YOLOv5 ðŸš€ v6.1-325-g3e85863 Python-3.7.13 torch-1.11.0+cu102 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 290 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/old-val/labels.cache' images and labels... 30 found, 0 missing, 0 empty, 0 corrupt: 100% 30/30 [00:00<?, ?it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.33s/it]\n",
      "                 all         30         69      0.992      0.957      0.981      0.798\n",
      "Speed: 0.1ms pre-process, 6.3ms inference, 1.8ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/exp9\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python yolov5/val.py --weights yolov5/runs/train/exp/weights/last.pt --data custom_data.yaml --img 640 --iou 0.65 --half"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate best resulting model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5OajNdXXFovn",
    "outputId": "235efa3e-3459-4c60-e367-d26283c0380a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolov5/data/custom_data.yaml, weights=['/content/gdrive/MyDrive/yolov5/models/best500m.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.65, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False\n",
      "YOLOv5 ðŸš€ v6.1-325-g3e85863 Python-3.7.13 torch-1.11.0+cu102 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 290 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/old-val/labels.cache' images and labels... 30 found, 0 missing, 0 empty, 0 corrupt: 100% 30/30 [00:00<?, ?it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.25s/it]\n",
      "                 all         30         69      0.994      0.957      0.976      0.807\n",
      "Speed: 0.1ms pre-process, 6.5ms inference, 1.9ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/exp11\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python yolov5/val.py --weights yolov5/runs/train/exp/weights/best.pt --data custom_data.yaml --img 640 --iou 0.65 --half"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0PhFkMOy7uV"
   },
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HJMZHRuZk0w"
   },
   "source": [
    "Export last resulting model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7CoNEp03Yx-L"
   },
   "outputs": [],
   "source": [
    "!python yolov5/export.py --weights yolov5/runs/train/exp/weights/last.pt --include onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNsYXUkRZmeZ"
   },
   "source": [
    "Export best resulting model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lb2U3HxTdp7f"
   },
   "outputs": [],
   "source": [
    "!python yolov5/export.py --weights yolov5/runs/train/exp/weights/best.pt --include onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3EGL8UpYTPG"
   },
   "source": [
    "## Download results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-CNWqJFTIFPt"
   },
   "outputs": [],
   "source": [
    "!zip -r /content/results.zip /content/yolov5\n",
    "from google.colab import files\n",
    "files.download(\"/content/results.zip\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CVProject Yolov5.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
